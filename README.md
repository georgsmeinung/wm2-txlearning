# Web Mining - Trabajo Práctico 2: Transfer Learning
**Los objetivos de este TP son**: 

- Ganar familiaridad con transfer learning, reentrenado a una red que ya había sido entrenado con imagenet, para que aprenda a clasificar tipos de flores. 
- Realizar varias pruebas para evaluar críticamente los resultados de transfer learning; no nos interesa que las respuestas del TP sean "da mejor", sino una hipótesis de por qué algo da mejor o peor. Si puede pensar en una manera de modificar el código o las imágenes para validar su hipótesis, y lo hace, aún mejor. 

**IMPORTANTE**: Las instrucciones de este TP referencian a notebooks de Collab. La URL para acceder a los notebooks de Collab de este TP es: 
[https://drive.google.com/drive/folders/1PAfLF-Dt5iE9Gk-f_jrQvfYBFfeozpo6?usp=sharing](https://drive.google.com/drive/folders/1PAfLF-Dt5iE9Gk-f_jrQvfYBFfeozpo6?usp=sharing)

**Recomendación general antes de comenzar el TP**

1. Como el código de este TP utiliza Tensorflow, antes de ejecutar un notebook en Collab, vaya al menú "Entorno de Ejecución" -> "Cambiar tipo de entorno de ejecución" -> "Acelerador de Hardware" = "GPU". Si no puede elegir GPU porque no hay disponibles, elija "TPU v4". Si no puede elegir TPU elija "CPU", pero la ejecución tomará mucho más tiempo. Si al ejecutar el notebook le da "Out of memory" (OOM), se debe a que la GPU que le asignó Collab no tiene suficiente memoria; esto pasa con las instancias gratis de Collab. En tal caso vuelva al menú "Entorno de Ejecución" y cambie a "Acelerador de Hardware" = "CPU". El TP se va a ejecutar más lento, pero se puede ejecutar igual. 

2. ¡CUIDADO! Los modelos entrenados en los notebooks se pierden cuando el backend del notebook se desconecta, a menos que ud. lo guarde a su gdrive, o al disco local. Es por eso que las notebooks en este TP guardan los resultados  a Google Drive. 

3. Si ve el error “ResourceExhaustedError” eso significa que una ejecución anterior reciente del notebook dejó cosas en memoria, y ahora no hay suficiente; cierre el notebook y vuelva a ejecutar todo desde el principio. 

## Pasos para poder ejecutar el TP: 
1. Cree una carpeta de nombre "collab" en la raíz de su google drive. Cree dentro una carpeta llamada “transfer_learning”
   
2. Copie el contenido de la carpeta “transfer learning” que está en [https://drive.google.com/drive/folders/1MGgeMuM9ESZrCYlfZnrG1abS1IJAcWIB?usp=sharing](https://drive.google.com/drive/folders/1MGgeMuM9ESZrCYlfZnrG1abS1IJAcWIB?usp=sharing) dentro de la carpeta llamada `collab/transfer_learning` en su google drive que acaba de crear.

3. Si todo está bien, debe aparecer una carpeta llamada "transfer_learning" dentro de la carpeta "collab", y adentro de “transfer_learning” debe tener 2 carpetas: imagenet_dataset y flowers_dataset. En particular, adentro de esa carpetas están los siguientes archivos: 
> - `transfer_learning/imagenet_dataset/vgg16_weights.h5`: contiene los pesos de la red VGG16 ya entrenada usando el dataset imagenet. 
> - `transfer_learning/imagenet_dataset/imagenet_class_index.json`: contiene los nombres de clase para las 1000 categorías de imagenet con la que fue entrenada VGG16. 
> - `transfer_learning/flowers_dataset/10FlowerColorImages.h5`: este archivo contiene 210 imágenes de 10 tipos distintos de flores (21 imágenes por tipo) guardadas dentro de un archivo en formato HDF5. Vamos a usar este archivo para hacer transfer learning de la NN ya entrenada. El contenido de este archivo son las imágenes en `transfer_learning/flowers_dataset/data/flower_images` junto con las categoría de cada flor en `transfer_learning/flowers_dataset/data/flower_images/flower_labels.csv`  
> - `transfer_learning/flowers_dataset/flower_class_index.txt`: contiene el nombre de cada una de las 10 clases de flores (clase 0=1ra línea, clase 2=2da línea, etc) 
> - `transfer_learning/flowers_dataset/data/test/flowers_holdout.h5`: Un dataset de prueba conteniendo imágenes de los mismos tipos de flores que están en el archivo de entrenamiento `10FlowerColorImages.h5`, pero estas son imágenes que no aparecen en ese archivo de entrenamiento . 
> - `transfer_learning/flowers_dataset/data/flower_images`: contiene copias de las imágenes individuales que están dentro del dataset de entrenamiento “10FlowerColorImages.h5”, para poder verlas. 
> - `transfer_learning/flowers_dataset/data/flower_images/flower_labels.csv`: contiene el tipo de flor de cada imagen en el dataset de entrenamiento. 
> - `transfer_learning/flowers_dataset/data/test`: contiene copias de las imágenes individuales que están dentro del dataset de test `flowers_holdout.h5`

4. Abra el notebook de collab "transfer learning 10 flowers", y presione "Activar GDrive" a la izquierda para que la carpeta "collab" de Gdrive que creó en el paso 1 pueda ser leída desde un notebook de Collab. 

## Preguntas a contestar: 
1. El notebook "transfer learning 10 flowers" contiene código para reemplazar y entrenar solo la capa final de clasificación de VGG16 ya entrenada con imagenet, de manera de poder clasificar otro dataset: las flores en el dataset “10 flowers”. Ejecútelo, y verá, por cada “epoch”, 2 valores (un epoch es una pasada de entrenamiento sobre el dataset de entrenamiento completo): 
> - **categorical_accuracy**: estimación de accuracy sobre el dataset de entrenamiento. 
> - **val_categorical_accuracy**: accuracy del clasificador evaluada sobre el dataset de validación. 
¿Qué resultados obtiene cuando entrena? Ejecútelo 5 veces; en cada ejecución el 30% de validación será diferente, y la transformación de ejemplos que genera ImageDataGenerator será diferente, así que puede obtener resultados diferentes. 
**¡MUY IMPORTANTE!** Note que el resultado de la ejecución exitosa de este notebook es un archivo llamado `vgg16_retrained_10flowers.keras` en Google Drive, que contiene la arquitectura + pesos de la red entrenada. Va a usar este archivo en pasos siguientes de este TP.

2. Hasta ahora ejecutamos el notebook "transfer learning 10 flowers" , que fue reentrenado con respecto a VGG16 cambiando solo la última capa de la red: la de clasificación. Modifique el notebook "transfer learning 10 flowers" para que ahora reentrene las 2 últimas capas de la red (en vez de sólo la última), y ejecútelo. ¿Qué resultados obtiene cuando reentrena, con respecto a los resultados de reentrenar modificando sólo la última capa como el punto 1?  

3. ¿Qué tienen de diferente los notebooks "transfer learning 10 flowers v2" y "transfer learning 10 flowers" (ignorando las diferencias en los comentarios) ? ¿Qué resultados obtiene cuando reentrena con "transfer learning 10 flowers v2" ? ¿Puede aventurar por qué? 

4. **Vuelva al notebook modificado en el paso 5**, para que reentrene `transfer learning 10 flowers`, que ud. ya modificó para que reentrene las 2 últimas capas de clasificación. En donde dice epochs=13, modifique el número de epochs al doble (26). Un “epoch”  es una pasada completa sobre el conjunto de entrenamiento; el entrenamiento de una red usualmente implica varias pasadas sobre el conjunto de entrenamiento. ¿Qué resultados de accuracy obtiene cuando reentrena comparado con el resultado cuando entrenaba con 13 epochs? ¿Cómo interpreta ese resultado? Guarde el clasificador resultante como `vgg16_retrained_10flowers_mejor.keras`. 

5. **Ejecute el notebook "test retrained vgg16"**. Este notebook lee el modelo `vgg16_retrained_10flowers_mejor.keras` entrenado anteriormente, y lo utiliza para clasificar las flores dentro de `transfer_learning/flowers_dataset/data/test/flowers_holdout.h5`. Este es un dataset de holdout conteniendo imágenes de flowers similares a las del dataset “10 Flowers”.La diferencia entre este conjunto de flores y el conjunto de entrenamiento es que estas flores son de los mismos tipos que el dataset 10 flowers, pero no aparecen en el dataset de entrenamiento, y las imágenes fueron elegidas para ser "difíciles". Las imagenes de este dataset están disponibles en `collab/transfer_learning/flowers_dataset/data/test`. En particular, las imagenes `viola_2.png` y `viola_3.png` contienen la misma flor, con el fondo coloreado de diferente color. ¿Qué resultados obtiene al ejecutar `test retrained vgg16`? En particular, ¿qué accuracy? ¿Qué patrones de error observa? ¿Cómo interpreta estos resultados con respecto al valor de accuracy obtenido al reentrenar VGG16? ¿Son creíbles? Puede comparar las flores de “10 flowers”, que están disponibles en `collab/transfer_learning/flowers_dataset/flower_images`. 

6. Los script de entrenamiento utilizan `ImageDataGenerator` para para generar mayor variedad de ejemplos al entrenar. `ImageDataGenerator` toma una imagen del dataset y le aplica ciertas transformaciones para generar ejemplos variados. Queremos evaluar ¿Qué efecto tiene la generación automática de ejemplos modificados durante el entrenamiento de la red: ¿Positivo, negativo, neutro? Para evaluar esto, en el notebook `transfer learning 10 flowers", en donde llama a `ImageDataGenerator`,  borre los parámetros `width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip`, y `rotation_range` pero conserve `preprocessing_function`; eso va a hacer que los ejemplos no se modifiquen en entrenamiento. Ejecute el notebook `transfer learning 10 flowers` para que vuelva a entrenar, y luego ejecute el notebook `test retrained vgg16` para evaluar. ¿Mejoran o empeoran los resultados al quitar la modificación de ejemplos? 

7. ¿Da lo mismo modificar las imágenes de ejemplo durante el entrenamiento de cualquier manera, o hay maneras de modificarla en donde la red que entrena mejor y peor? En otras palabras: ¿Que tan resistente es la red a los ejemplos modificados? ¿Sirve cualquier modificación de ejemplos? Para evaluar esto, en el notebook `transfer learning 10 flowers`, en donde llama a `ImageDataGenerator`, anote los valores actuales de los parámetros, y luego agregue o modifique los parámetros de `ImageDataGenerato` así: `width_shift_range=0.1, height_shift_range=0.1, shear_range=0, zoom_range=0.5, horizontal_flip=True`, y `rotation_range=20`. Ejecute el notebook `transfer learning 10 flowers` para que vuelva a entrenar, y luego ejecute el notebook `test retrained vgg16` para evaluar. ¿Qué tienen de diferente estos parámetros con respecto a los que se usaron originalmente para entrenar? ¿Mejoran o empeoran los resultados al quitar la modificación de ejemplos? ¿Hay transformaciones que tienen más efectos que otras para este dataset? 

8. Si en el notebook “transfer learning 10 flowers” reemplaza: `callbacks=[EarlyStopping(monitor='val_categorical_accuracy', patience=epochs_to_stop_after_no_improvement, verbose=1), ModelCheckpoint('/content/drive/MyDrive/collab/transfer_learning/vgg16_retrained_10flowers.keras', verbose=1, monitor='val_categorical_accuracy', save_best_only=True, mode='auto')]` por: `callbacks=[EarlyStopping(monitor='categorical_accuracy', patience=epochs_to_stop_after_no_improvement, verbose=1), ModelCheckpoint('/content/drive/MyDrive/collab/transfer_learning/vgg16_retrained_10flowers.keras', verbose=1, monitor='categorical_accuracy', save_best_only=True, mode='auto')]` ¿Qué cambia en el entrenamiento? ¿Qué criterio está usando luego del cambio para decidir si sigue entrenando? Google es su amigo. 
